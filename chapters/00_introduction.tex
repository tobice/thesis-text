\chapter*{Introduction}
\addcontentsline{toc}{chapter}{Introduction}

The Internet of today is full of data and the amount is constantly increasing. By data we mean literary anything that can be found online, may it be a huge source of organized information like Wikipedia or a small table created with Microsoft Excel by a local government office. Unfortunately, our ability to use the whole potential of all currently available data is very limited. We want to to explore the data, we want to connect and combine different data sets, we want to look for patterns in the data, we want to make the data available to end users. All of that is possible, yet usually time and resources demanding. 

Let us consider for example the aforementioned table produced by Microsoft Excel.  XLSX is a proprietary format that can be officially opened only by a paid proprietary software. This software offers a large yet still limited set of tools. It may very well happen that it will not allow us to do what we want. Given the topic of this thesis, let us say that we want to create from the table a new specialized interactive visualization (or an \textit{application}) and publish it online. To get this done,  we would most likely need a computer specialist or  even a developer. Those people are relatively rare and expensive.

Tools that attempt to solve this particular problem are called \emph{application generators}. They allow non-developers to do developers' work which in this case means to generate from the data an interactive (possibly online) application. Such generators already exist, for example for the aforementioned XLSX format (or in general for tabular data) but they are usually very limited. One reason for this limitation is that the tabular data carry very little semantic information with them. One row represents an entity and each column contains one entity attribute. The first row might (or might not) contain labels for the attributes. That is all that the tabular data based generator can work with.

One of the positive recent trends is that more and more information is published using the Resource Description Framework \cite{rdf} while utilizing the Linked Data model \cite{ld}. Besides being open and offering a natural way of linking and combining different data sets, this framework is able to express any kind of information by extending the raw data with machine-readable semantic meta-data. In other words, data represented in RDF are, unlike the tabular data, not limited in what semantic information they can carry with them. A Linked Data driven application generator could benefit significantly from this feature. As such a generator could literary \textit{understand} the data, it would allow the user to generate way more versatile applications, tailored for all different kinds of data. 
% * <tobiaspotocek@gmail.com> 2016-06-09T10:02:42.253Z:
%
% >  A Linked Data driven application generator could benefit significantly from this feature
%
% Perhaps incorporate somewhere that there already exist lots of existing Linked Data applications but the goal is to make the creation process of new ones simpler.
%
% ^ <tobiaspotocek@gmail.com> 2016-06-09T10:10:59.089Z:
%
% Eg. There is an application called Justinian. It's hard to imagine that a non-developer user could create such a complex application. But the framework could be of great help.
%
% ^.

The main goal of this thesis will be to create such a Linked Data driven application generator. That means, as already suggested, that we will be focusing on allowing the non-developers do developers' work. Obviously, that is possible only to a certain extent. The data represented in RDF can be understood with software, but first someone (the developer) has to teach the software how to understand it. For example, for data containing geospatial information (RDF offers a way how to describe such information), the developer would have to extend the generator with a plugin showing such data on a~map.

\textit{Fill in the gap}

\section*{Goal of this thesis}

The goal of this thesis will be to create a Linked Data based application generator with all the features listed in the previous section. The application generator will work as a \textit{framework}, easily extendable with new visualization plugins that will allow generating applications from different types of data. It will define a clear interface that the new plugins will have to implement. Also many documented drop-in solutions for typical problems and situations will be available for the developer.

The application generator will also be a \textit{platform}, providing space for developers to register new plugins, space for data analyst to publish new data sets and space for common users to generate, manage and publish their applications.

Besides the generator itself, we will also implement two visualizer plugins to demonstrate the abilities of the \textit{framework} and the \textit{platform}.

\section*{Structure of the text}

In Chapter 1, we briefly describe RDF and Linked Data and provide related information necessary for understanding the rest of the thesis. In Chapter 2, we focus on similar existing tools and compare them to our proposed generator. In Chapter 3, we examine in depth the tool LinkedPipes as we will base our generator on top of it.  In Chapter 4, we look more in detail into the required features and we present steps and decisions necessary for achieving our goals. In this chapter, we also analyze and defend our decision to use LinkedPipes as a base for our generator, plus we describe how it has to be modified to fit our intentions. In Chapter 5, we dive into implementation details. Especially we focus on the framework aspect. We show how a new visualizer plugin can be integrated into the generator and what tools are available for the developer. In Chapter 6, we describe in detail the two visualizer plugins, D3.js Chord Visualizer and Google Maps Visualizer, that we implemented to demonstrate our generator's abilities. Related to the D3.js Chord Visualizer, there is a short theoretical part in this chapter that deals with representing and sampling graph structures (actual graphs as understood in graph theory) using RDF and SPARQL queries. In the final Chapter 7, we describe possible future work.